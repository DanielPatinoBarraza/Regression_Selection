{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b239ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import datetime \n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from scipy.stats import pearsonr\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "# from factor_analyzer import FactorAnalyzer # Ánalisis factorial\n",
    "from scipy.stats import bartlett\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import multiprocessing\n",
    "# from regressors import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.inspection import permutation_importance\n",
    "import multiprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn import tree\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "\n",
    "# Configuración matplotlib\n",
    "# ==============================================================================\n",
    "plt.rcParams['image.cmap'] = \"bwr\"\n",
    "#plt.rcParams['figure.dpi'] = \"100\"\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n",
    "import matplotlib.font_manager\n",
    "from matplotlib import style\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a6933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to train\n",
    "forest_model = dict(model=RandomForestRegressor(), \n",
    "                        hyperparams_space=dict(n_estimators = [10, 100, 300],\n",
    "                                               max_features= [2, 4, 6], \n",
    "                                               max_depth=[int(x) for x in np.linspace(2, 50, num = 10)]))\n",
    "    \n",
    "ridge_model = dict(model=Ridge(), hyperparams_space=dict(alpha = np.linspace(0, 1, 20)))\n",
    "\n",
    "svr_model = dict(model=svm.SVR(), hyperparams_space = {\n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': [1e-4, 1e-3, 0.01, 0.1, 0.2, 0.5, 0.6, 0.9],\n",
    "        'C': [1, 10, 100, 1000, 10000]})\n",
    "    \n",
    "xgb_model = dict(model=xgb.XGBRegressor(), hyperparams_space= {\n",
    "    \"n_estimators\":[int(x) for x in np.linspace(start = 100, stop = 500, num = 10)],\n",
    "        \"max_depth\": [int(x) for x in np.linspace(10, 110, num = 10)],\n",
    "        \"eta\":[x for x in np.linspace(0, 1, num = 10)],\n",
    "        \"max_leaves\": [int(x) for x in np.linspace(0, 110, num = 10)],})\n",
    "    \n",
    "SDG_model= dict(model=SGDRegressor(),hyperparams_space= {\"penalty\":[\"l2\", \"l1\", \"elasticnet\"] ,\n",
    "                                                         \"alpha\": [1e-7,1e-6,1e-5,1e-4, 1e-3] ,\n",
    "                                                        \"learning_rate\":[\"constant\",\"optimal\",\"invscaling\",\"adaptive\"]})  \n",
    "\n",
    "knn_model =  dict(model= KNeighborsRegressor(), hyperparams_space={\"n_neighbors\":[int(x) for x in np.linspace(1, len(dataframes[0])/3, num = 10)]})\n",
    "    \n",
    "    \n",
    "    \n",
    "Hist_model= dict(model=HistGradientBoostingRegressor(), hyperparams_space={\"loss\":[\"least_squares\", \"least_absolute_deviation\", \"poisson\"]}) \n",
    "\n",
    "\n",
    "MLP_model= dict(model=MLPRegressor(),   hyperparams_space={\"activation\":[\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "\"alpha\": [1e-7,1e-6,1e-5,1e-4, 1e-3],\n",
    "\"learning_rate\":[\"constant\", \"invscaling\", \"adaptive\"] })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caebbada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cross_validation(X, y, models: list, outer_n_splits=10, inner_n_splits=3, random_state=1):\n",
    "    cv_outer = KFold(n_splits=outer_n_splits, shuffle=True, random_state=random_state)\n",
    "    results = {}\n",
    "    results_metrics = {}\n",
    "    metrics = [\"mse\", \"rmse\", \"r2\", \"mae\"]\n",
    "    for model in models:\n",
    "        model[\"name\"] = model[\"model\"].__class__.__name__\n",
    "        results[model[\"name\"]] = dict(metrics={\"mse\": [], \"rmse\": [], \"r2\": [], \"mae\": []}, best_model_score = -1)\n",
    "        results_metrics[model[\"name\"]] = {metric:[] for metric in metrics}\n",
    "    for train_ix, test_ix in cv_outer.split(X):\n",
    "        X_train, X_test = X[train_ix, :], X[test_ix, :]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        cv_inner = KFold(n_splits=inner_n_splits, shuffle=True, random_state=random_state)\n",
    "        for model in models:\n",
    "            try:\n",
    "                model[\"model\"].set_params(**{\"random_state\": random_state})\n",
    "            except:\n",
    "                pass\n",
    "            # define search\n",
    "            search = RandomizedSearchCV(model[\"model\"], \n",
    "                                               model[\"hyperparams_space\"], \n",
    "                                               #scoring='neg_mean_squared_error', \n",
    "                                               scoring='r2',\n",
    "                                               cv=cv_inner, refit=True)\n",
    "            # execute search\n",
    "            result = search.fit(X_train, y_train)\n",
    "            # get the best performing model fit on the whole training set\n",
    "            current_best_model = result.best_estimator_\n",
    "            # evaluate model on the hold out dataset\n",
    "            yhat = current_best_model.predict(X_test)\n",
    " \n",
    "            # evaluate the model\n",
    "            mse = mean_squared_error(y_test, yhat)\n",
    "            mae = mean_absolute_error(y_test, yhat)\n",
    "            rmse = np.sqrt(mse)\n",
    "            r2 = r2_score(y_test, yhat)\n",
    "\n",
    "            # store the result\n",
    "            results_metrics[model[\"name\"]][\"mae\"].append(mae)\n",
    "            results_metrics[model[\"name\"]][\"mse\"].append(mse)\n",
    "            results_metrics[model[\"name\"]][\"rmse\"].append(rmse)\n",
    "            results_metrics[model[\"name\"]][\"r2\"].append(r2)\n",
    "                \n",
    "            if r2 > results[model[\"name\"]][\"best_model_score\"]:\n",
    "                results[model[\"name\"]][\"best_model_score\"] = r2\n",
    "                results[model[\"name\"]][\"best_model_cfg\"] = result.best_params_\n",
    "                results[model[\"name\"]][\"best_model\"] = current_best_model\n",
    "            # report progress\n",
    "            #print(f'>{model[\"name\"]} mse={mse:.4f}, rmse={rmse:.4f}, cfg={result.best_params_}')\n",
    "        #print()\n",
    "       \n",
    "        # summarize the estimated performance of the model and get the best one\n",
    "        best_model_score = -1\n",
    "        for model in models:\n",
    "            current_metrics = results_metrics[model[\"name\"]][\"r2\"]\n",
    "            mean_current_metrics = np.mean(current_metrics)\n",
    "            if mean_current_metrics > best_model_score:\n",
    "                best_model_score = mean_current_metrics\n",
    "                best_model_sd = np.std(current_metrics)\n",
    "                best_model = results[model[\"name\"]][\"best_model\"]\n",
    "                best_model_cfg = results[model[\"name\"]][\"best_model_cfg\"]\n",
    "    table_result = pd.DataFrame(results)\n",
    "    best_model_name = best_model.__class__.__name__\n",
    "    print(f\"El mejor modelo es: {best_model_name}\")\n",
    "    print(f\"best_model_score R2 {best_model_score}\")\n",
    "    print(f\"best_model_score STD {best_model_sd}\")\n",
    "    print(f\"best_model selected r2  {results_metrics[best_model_name]['r2']}\")\n",
    "    print(f\"best_model_cfg {best_model_cfg}\")   \n",
    "    for model in models:\n",
    "        for metric in metrics:\n",
    "            results_metrics[model[\"name\"]][metric] = np.mean(results_metrics[model[\"name\"]][metric])\n",
    "    return best_model, pd.DataFrame(results_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e315ba8",
   "metadata": {},
   "source": [
    "Solo hay que seleccionar el X, Y, para probar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf804c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, result_metrics = nested_cross_validation(X, y, [forest_model,svr_model, xgb_model,SDG_model,knn_model,Hist_model,MLP_model])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
